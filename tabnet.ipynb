{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76e34a2b-b2b5-4810-bca8-6955cd00f693",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 08:40:09.431879: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import torch\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import xgboost as xgb\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from typing import Tuple\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f363f20-af15-4aab-9fc8-f5bfd5ed9472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(myFunction):\n",
    "    def functionTimer(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = myFunction(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        computation_time = round(end_time - start_time, 2)\n",
    "        print(\"{} is executed\".format(myFunction.__name__), end=\" \")\n",
    "        print('(took: {:.2f} seconds)'.format(computation_time))\n",
    "        return result\n",
    "    return functionTimer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "093c6985-2206-48ac-93aa-e76f1d467631",
   "metadata": {},
   "outputs": [],
   "source": [
    "@timer\n",
    "def prepareData(X: \"pd.dataFrame\", impute_numericals, impute_categories, encode_categories, imputation_type='simple', numcores=6) -> \"pd.dataFrame\":\n",
    "    try:\n",
    "        X.drop(columns=['customer_ID'], inplace=True)\n",
    "        print(\"dropped customer_ID.\", end=\" \")\n",
    "    except:\n",
    "        None\n",
    "\n",
    "    if impute_categories:\n",
    "        cols = [col for col in X.columns if col[:-6] in ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']]\n",
    "#        cols=list(X[X[cols].select_dtypes(include=['object']).columns].isna().any().index)\n",
    "        imp = SimpleImputer(missing_values=np.nan, strategy='constant')\n",
    "        imp.fit(X[cols])\n",
    "        X[cols]=imp.transform(X[cols])\n",
    "        X[cols] = X[cols].astype(\"str\")\n",
    "        print(\"imputed categoricals.\", end=\" \")\n",
    "\n",
    "    if encode_categories:\n",
    "        cols = [col for col in X.columns if col[:-6] in ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']]\n",
    "        X[cols] = X[cols].astype(\"str\")\n",
    "        X[cols] = X[cols].astype(\"category\")\n",
    "        enc = OrdinalEncoder()\n",
    "        enc.fit(X[cols])\n",
    "        X[cols]=enc.transform(X[cols])\n",
    "        print(\"encoded categories.\", end=\" \")\n",
    "        X[cols] = X[cols].astype(\"category\")\n",
    "\n",
    "    if impute_numericals:\n",
    "        cols=list(X.select_dtypes(include=['int64', 'float64']).columns[X.select_dtypes(include=['int64', 'float64']).isna().any()])\n",
    "        #cols=list(cols - set(X.select_dtypes(include=['int64', 'float64']).columns[X.select_dtypes(include=['int64', 'float64']).notna().all()]))\n",
    "        params = {\n",
    "                    'gpu_id' : 0,\n",
    "                    'tree_method' : 'gpu_hist'\n",
    "        }\n",
    "\n",
    "        if imputation_type == 'knn':\n",
    "            imp = KNNImputer()\n",
    "        else:\n",
    "            imp = SimpleImputer(strategy='median')\n",
    "#        imp.set_params(params)\n",
    "        X[cols] = imp.fit_transform(X[cols])\n",
    "        print(\"imputed numericals.\", end=\" \")\n",
    "\n",
    "    return X\n",
    "\n",
    "@timer\n",
    "def splitData(X: \"pd.dataFrame\"):\n",
    "    y=X['target']\n",
    "    X.drop(columns=['target'], inplace=True)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.1)\n",
    "    print(\"train/test done.\")\n",
    "\n",
    "#    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train,test_size=0.1)\n",
    "#    print(\"train/validation done.\", end=\" \")\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dbe90f3-890b-47a3-b232-3f9df4047c7f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standardise the data sets\n",
    "@timer\n",
    "def standardiseNumericalFeats(X_train, X_test):\n",
    "    \"\"\"Standardise the numerical features\n",
    "    \n",
    "    Returns:\n",
    "        Standardised X_train and X_test\n",
    "    \"\"\"\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    cols=list(X_train.select_dtypes(include=['int64', 'float64']).columns[X.select_dtypes(include=['int64', 'float64']).isna().any()])\n",
    "    for col in numerical_cols:\n",
    "        X_train[col] = scaler.fit_transform(X_train[[col]])\n",
    "        X_test[col] = scaler.transform(X_test[[col]])\n",
    "        \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "16117dbd-8403-4a5e-babd-86145f522894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def amex_metric(y_pred: pd.DataFrame, y_true: pd.DataFrame)  -> Tuple[str, float]:\n",
    "    def top_four_percent_captured(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        four_pct_cutoff = int(0.04 * df['weight'].sum())\n",
    "        df['weight_cumsum'] = df['weight'].cumsum()\n",
    "        df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n",
    "#        print('tfpc:', (df_cutoff['target'] == 1).sum() / (df['target'] == 1).sum())\n",
    "#        df.to_csv('tfpc'+str(len(df))+'.csv', index=False)\n",
    "        return (df_cutoff['target'] == 1).sum() / (df['target'] == 1).sum()\n",
    "        \n",
    "    def weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        df['random'] = (df['weight'] / df['weight'].sum()).cumsum()\n",
    "        total_pos = (df['target'] * df['weight']).sum()\n",
    "        df['cum_pos_found'] = (df['target'] * df['weight']).cumsum()\n",
    "        df['lorentz'] = df['cum_pos_found'] / total_pos\n",
    "        df['gini'] = (df['lorentz'] - df['random']) * df['weight']\n",
    "#        df.to_csv('wg'+str(len(df))+'.csv', index=False)\n",
    "#        print('gsum:', df['gini'].sum())\n",
    "        return df['gini'].sum()\n",
    "\n",
    "    def normalized_weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        y_true_pred = y_true.rename(columns={'target': 'prediction'})\n",
    "        return weighted_gini(y_true, y_pred) / weighted_gini(y_true, y_true_pred)\n",
    "\n",
    "    yt =pd.DataFrame(y_true.get_label(), columns=['target'])\n",
    "    yp =pd.DataFrame(y_pred, columns=['prediction'])\n",
    "    g = normalized_weighted_gini(yt, yp)\n",
    "    d = top_four_percent_captured(yt, yp)\n",
    "    print('g:', g, 'd:', d)\n",
    "\n",
    "    return 'amexmetric', (0.5 * (g+d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e81ba7c6-b30e-403d-a521-e8fd055ae245",
   "metadata": {},
   "outputs": [],
   "source": [
    "@timer\n",
    "def trainXgbModel(X_train, y_train, X_test, y_test, FEATS, ROUNDS) -> \"XGBoost model obj\":    \n",
    "    params = {\n",
    "                'eta': 0.02,\n",
    "                'max_depth': 10,\n",
    "                'min_child_weight': 7,\n",
    "                'subsample': 0.6,\n",
    "                'objective': 'binary:logistic',\n",
    "#                'objective': 'rank:ndcg',\n",
    "#                'objective': 'reg:squarederror',\n",
    "                'eval_metric': ['rmse', 'rmsle', 'auc'],\n",
    "#                'grow_policy': 'lossguide',\n",
    "                'gpu_id' : 0,\n",
    "                'tree_method' : 'gpu_hist',\n",
    "                'disable_default_eval_metric': 1\n",
    "        }\n",
    "\n",
    "    dtrain, dtest = xgb.DMatrix(X_train, y_train, feature_names=FEATS, enable_categorical=True), xgb.DMatrix(X_test, y_test, feature_names=FEATS, enable_categorical=True)\n",
    "\n",
    "    EVAL_LIST = [(dtrain, \"train\"),(dtest, \"test\")]\n",
    "\n",
    "#    xgb_model = xgb.train(params,dtrain,ROUNDS,EVAL_LIST, early_stopping_rounds = 300, feval=amex_metric)\n",
    "    xgb_model = xgb.train(params,dtrain,ROUNDS,EVAL_LIST, feval=amex_metric)\n",
    "    \n",
    "    return xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14ad4a35-a7e3-408a-91da-01fe810c06eb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@timer\n",
    "def trainD1CnnModel(X_train, y_train):\n",
    "    \"\"\"Train D1-CNN model\n",
    "    \n",
    "    Return:\n",
    "        keras model obj\n",
    "    \"\"\"\n",
    "\n",
    "    d1_cnn_model = keras.Sequential([\n",
    "        layers.Dense(4096, activation='relu'),\n",
    "        layers.Reshape((256, 16)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Conv1D(filters=16, kernel_size=5, strides=1, activation='relu'),\n",
    "        layers.MaxPooling1D(pool_size=2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(16, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid'),\n",
    "    ])\n",
    "\n",
    "    d1_cnn_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=3e-3),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[keras.metrics.BinaryCrossentropy()]\n",
    "    )\n",
    "\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        patience=25,\n",
    "        min_delta=0.001,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "    d1_cnn_model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=10000,\n",
    "        epochs=5000,\n",
    "        callbacks=[early_stopping],\n",
    "        validation_data=(X_test, y_test),\n",
    "    )\n",
    "    \n",
    "    return d1_cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "73e4c579-57ac-43a0-8145-d938509da827",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@timer\n",
    "def trainTabNetModel(X_train, y_train, pretrainer):\n",
    "    \"\"\"Train TabNet model\n",
    "    \n",
    "    Args:\n",
    "        pretrainer: pretrained model. If not using this, use None\n",
    "        \n",
    "    Return:\n",
    "        TabNet model obj\n",
    "    \"\"\"\n",
    "    \n",
    "    tabNet_model = TabNetClassifier(\n",
    "                                   n_d=16,\n",
    "                                   n_a=16,\n",
    "                                   n_steps=4,\n",
    "                                   gamma=1.9,\n",
    "                                   n_independent=4,\n",
    "                                   n_shared=5,\n",
    "                                   seed=42,\n",
    "                                   optimizer_fn = torch.optim.Adam,\n",
    "                                   scheduler_params = {\"milestones\": [150,250,300,350,400,450],'gamma':0.2},\n",
    "                                   scheduler_fn=torch.optim.lr_scheduler.MultiStepLR\n",
    "                                  )\n",
    "\n",
    "    tabNet_model.fit(\n",
    "        X_train = X_train.to_numpy(),\n",
    "        y_train = y_train.to_numpy(),\n",
    "        eval_set=[(X_train.to_numpy(), y_train.to_numpy()),\n",
    "                  (X_test.to_numpy(), y_test.to_numpy())],\n",
    "        max_epochs = 100,\n",
    "        batch_size = 256,\n",
    "        patience = 10,\n",
    "        from_unsupervised = pretrainer\n",
    "        )\n",
    "    \n",
    "    return tabNet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7d91cfde-5874-42ed-8f6b-029e5ae25f2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@timer\n",
    "def tabNetPretrain(X_train):\n",
    "    \"\"\"Pretrain TabNet model\n",
    "    \n",
    "    Return:\n",
    "        TabNet pretrainer obj\n",
    "    \"\"\"\n",
    "    tabnet_params = dict(n_d=8, n_a=8, n_steps=3, gamma=1.3,\n",
    "                             n_independent=2, n_shared=2,\n",
    "                             seed=42, lambda_sparse=1e-3,\n",
    "                             optimizer_fn=torch.optim.Adam,\n",
    "                             optimizer_params=dict(lr=2e-2,\n",
    "                                                   weight_decay=1e-5\n",
    "                                                  ),\n",
    "                             mask_type=\"entmax\",\n",
    "                             scheduler_params=dict(max_lr=0.05,\n",
    "                                                   steps_per_epoch=int(X_train.shape[0] / 256),\n",
    "                                                   epochs=200,\n",
    "                                                   is_batch_level=True\n",
    "                                                  ),\n",
    "                             scheduler_fn=torch.optim.lr_scheduler.OneCycleLR,\n",
    "                             verbose=10\n",
    "                        )\n",
    "\n",
    "    pretrainer = TabNetPretrainer(**tabnet_params)\n",
    "\n",
    "    pretrainer.fit(\n",
    "        X_train=X_train.to_numpy(),\n",
    "        eval_set=[X_train.to_numpy()],\n",
    "        max_epochs = 100,\n",
    "        patience = 10, \n",
    "        batch_size = 256, \n",
    "        virtual_batch_size = 128,\n",
    "        num_workers = 1, \n",
    "        drop_last = True)\n",
    "    \n",
    "    return pretrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe0f2a1a-60bf-458d-9413-de9707d46ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "@timer\n",
    "def makePredictions(X_test, xgb_model, d1_cnn_model, tabNet_model):\n",
    "    \"\"\"Make predictions\n",
    "    \n",
    "    Return:\n",
    "        Predictions from each models\n",
    "    \"\"\"\n",
    "\n",
    "    y_xgb_pred = None\n",
    "    y_d1_cnn_pred = None\n",
    "    y_tabNet_pred = None\n",
    "\n",
    "    if xgb_model is not None:\n",
    "        y_xgb_pred = xgb_model.predict(xgb.DMatrix(X_test, enable_categorical=True))\n",
    "    if d1_cnn_model is not None:\n",
    "        y_d1_cnn_pred = d1_cnn_model.predict(X_test).reshape(1, -1)[0]\n",
    "    if tabNet_model is not None:\n",
    "        y_tabNet_pred = tabNet_model.predict_proba(X_test.to_numpy())[:,1]\n",
    "    \n",
    "    return [y_xgb_pred, y_d1_cnn_pred, y_tabNet_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2120fe64-7164-4352-b900-6b6beaeafe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "@timer\n",
    "def evaluate(y_test, y_xgb_pred, y_d1_cnn_pred, y_tabNet_pred) -> None:\n",
    "    \"\"\"Evaluate the predictions\n",
    "    \n",
    "    Process:\n",
    "        Print ROC AUC and F1 score of each models\n",
    "    \"\"\"\n",
    "    preds = {}\n",
    "    if y_xgb_pred is not None:\n",
    "        preds['XGBoost'] = y_xgb_pred\n",
    "    if y_d1_cnn_pred is not None:\n",
    "        preds['D1 CNN'] = y_d1cnn_pred\n",
    "    if y_tabNet_pred is not None:\n",
    "        preds['TabNet'] = y_tabNet_pred\n",
    "#    preds = {\"XGBoost\":y_xgb_pred, \"D1 CNN\":y_d1_cnn_pred, \"TabNet\":y_tabNet_pred}\n",
    "\n",
    "#    print(preds)\n",
    "    for key in preds:\n",
    "        print(\"The ROC AUC score of \"+ str(key) +\" model is \" +\n",
    "              str(round(roc_auc_score(y_test, preds[key]), 4))\n",
    "             )\n",
    "\n",
    "    for key in preds:\n",
    "        print(\"The F1 score of \"+ str(key) +\" model at threshold = 0.27 is \" +\n",
    "              str(round(f1_score(y_test, np.where(preds[key] > 0.27, 1, 0)), 4))\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "999100c0-737c-4a60-9b3e-87e9bebe95f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot prediction distribution\n",
    "def plotPredictionDistribution(y_xgb_pred, y_d1_cnn_pred, y_tabNet_pred) -> None:\n",
    "    \"\"\"Plot histogram of predicted probability distributions of each model\n",
    "    \"\"\"\n",
    "\n",
    "    preds = {}\n",
    "    if y_xgb_pred is not None:\n",
    "        preds['XGBoost'] = y_xgb_pred\n",
    "    if y_d1_cnn_pred is not None:\n",
    "        preds['D1 CNN'] = y_d1cnn_pred\n",
    "    if y_tabNet_pred is not None:\n",
    "        preds['TabNet'] = y_tabNet_pred\n",
    "#    preds = {\"XGBoost\":y_xgb_pred, \"D1 CNN\":y_d1_cnn_pred, \"TabNet\":y_tabNet_pred}\n",
    "\n",
    "    for key in preds:\n",
    "        plt.hist(preds[key], bins = 100)\n",
    "        plt.title(f\"Predicted probability distribution of {key}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "950fd776-4a1b-49a0-a170-6a3be900fb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@timer\n",
    "def readData(tag, frange, fstart=0):\n",
    "    traindf=pd.DataFrame()\n",
    "    for i in range(fstart, frange):\n",
    "        print(\"x\" + tag + str(i), end=\" \")\n",
    "        traindf = pd.concat([traindf, pd.read_csv(\"x\" + tag + str(i) + \"dtcnt.csv\")], ignore_index=True)\n",
    "\n",
    "    [traindf[col].astype('category') for col in traindf.columns if (col[:len(col)-6] in ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']) or ('yearmonth' in col) or ('day_of_week' in col)]\n",
    "    #    traindf[col] = traindf[col].astype('category')\n",
    "    #print(\"updated categories...\")\n",
    "\n",
    "    return traindf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9565fec-9493-49ea-b4ec-8d4cd6184bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@timer\n",
    "def balancedata(X_train: \"pd.dataFrame\", y_train: \"pd.dataFrame\") -> (\"pd.dataFrame\", \"pd.dataFrame\"):\n",
    "    sm = SMOTE(random_state = 2)\n",
    "    X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel())\n",
    "    print(\"The ratio of target class in training set is \" + str(round(y_train_res.sum()/len(y_train_res) * 100, 2)) + \"%\")\n",
    "    print(\"Len of X_train is\", len(X_train), \" & X_train_res is\", len(X_train_res))\n",
    "    return X_train_res, y_train_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "306684c6-426c-41bc-a285-780a54c573c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the data x0 x1 x2 x3 x4 x5 x6 x7 x8 x9 x10 x11 readData is executed (took: 22.55 seconds)\n",
      "Preprocessing the data dropped customer_ID. imputed categoricals. encoded categories. imputed numericals. prepareData is executed (took: 761.22 seconds)\n",
      "The ratio of target class in training set is 50.0%\n",
      "Len of X_train is 63283  & X_train_res is 72496\n",
      "balancedata is executed (took: 435.50 seconds)\n",
      "\n",
      "train/test done.\n",
      "splitData is executed (took: 3.36 seconds)\n",
      "The ratio of target class in training set is 49.98%\n",
      "The ratio of target class in test set is 50.18%\n"
     ]
    }
   ],
   "source": [
    "#Load and split the data\n",
    "\n",
    "ROUNDS = 51\n",
    "loads=[False, True, True, True] # [csv, xgb, d1cnn, tabnet]\n",
    "nof, fstart=12, 0\n",
    "fprefix=\"\" #str(nof)\n",
    "ftag = \"\".join([str(i) for i in range(nof)])\n",
    "ftag=\"all\"\n",
    "\n",
    "if loads[0]:\n",
    "    print(\"Loading the data\", \"X\" + fprefix + ftag + \"bal.csv\", end=\" \")\n",
    "    X = pd.read_csv(\"X\" + fprefix + ftag + \"bal.csv\")\n",
    "else:\n",
    "    print(\"Reading the data\", end=\" \")\n",
    "    df = readData(fprefix, nof, fstart)\n",
    "    print(\"Preprocessing the data\", end=\" \")\n",
    "    X=prepareData(df.loc[:, ~df.isnull().all()], True, True, True)\n",
    "    X.to_csv(\"X\" + fprefix + ftag + \".csv\", index=False)\n",
    "    y=X['target']\n",
    "    X_train_res, y_train_res = balancedata(X, y)\n",
    "    if 'target' not in X.columns:\n",
    "        X=pd.concat([X_train_res, pd.DataFrame(y_train_res, columns=[\"target\"])], axis='columns')\n",
    "    else:\n",
    "        X= X_train_res\n",
    "    X.to_csv(\"X\" + fprefix + ftag + \"bal.csv\", index=False)\n",
    "\n",
    "print(\"\")\n",
    "y=X['target']\n",
    "\n",
    "FEATS = [col for col in X.columns if (col[:len(col)-6] in ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']) or ('yearmonth' in col) or ('day_of_week' in col) or ('day_of_month') in col or ('day_of_year' in col)]\n",
    "\n",
    "X_train, y_train, X_test, y_test = splitData(X)\n",
    "\n",
    "print(\"The ratio of target class in training set is \" + str(round(y_train.sum()/len(y_train) * 100, 2)) + \"%\")\n",
    "print(\"The ratio of target class in test set is \" + str(round(y_test.sum()/len(y_test) * 100, 2)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e80a2dc6-8eec-4964-80d9-dec9b82f9d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading XGBoost model\n",
      "Training TabNet model\n",
      "Device used : cuda\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [55]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining TabNet model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m#    tabNet_model = trainTabNetModel(X_train, y_train, None)\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m     tabNet_model \u001b[38;5;241m=\u001b[39m trainTabNetModel(X_train_res, y_train_res, \u001b[43mtabNetPretrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     38\u001b[0m     tabNet_model\u001b[38;5;241m.\u001b[39msave_model(tag\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m ftag \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mtimer.<locals>.functionTimer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunctionTimer\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m      3\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 4\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mmyFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      6\u001b[0m     computation_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(end_time \u001b[38;5;241m-\u001b[39m start_time, \u001b[38;5;241m2\u001b[39m)\n",
      "Input \u001b[0;32mIn [42]\u001b[0m, in \u001b[0;36mtabNetPretrain\u001b[0;34m(X_train)\u001b[0m\n\u001b[1;32m      8\u001b[0m tabnet_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(n_d\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, n_a\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, n_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.3\u001b[39m,\n\u001b[1;32m      9\u001b[0m                          n_independent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, n_shared\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     10\u001b[0m                          seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, lambda_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m                          verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     23\u001b[0m                     )\n\u001b[1;32m     25\u001b[0m pretrainer \u001b[38;5;241m=\u001b[39m TabNetPretrainer(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtabnet_params)\n\u001b[0;32m---> 27\u001b[0m \u001b[43mpretrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvirtual_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pretrainer\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_tabnet/pretraining.py:121\u001b[0m, in \u001b[0;36mTabNetPretrainer.fit\u001b[0;34m(self, X_train, eval_set, eval_name, loss_fn, pretraining_ratio, weights, max_epochs, patience, batch_size, virtual_batch_size, num_workers, drop_last, callbacks, pin_memory)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn \u001b[38;5;241m=\u001b[39m loss_fn\n\u001b[0;32m--> 121\u001b[0m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_fit_params(\n\u001b[1;32m    124\u001b[0m     weights,\n\u001b[1;32m    125\u001b[0m )\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# Validate and reformat eval set depending on training data\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:72\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPass \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m as keyword args. From version 0.25 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     68\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassing these as positional arguments will \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     69\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult in an error\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(args_msg)),\n\u001b[1;32m     70\u001b[0m                   \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[1;32m     71\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate({k: arg \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args)})\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:644\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    641\u001b[0m                          \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name))\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 644\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    648\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:96\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (allow_nan \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misinf(X)\u001b[38;5;241m.\u001b[39many() \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m     94\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m allow_nan \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(X)\u001b[38;5;241m.\u001b[39mall()):\n\u001b[1;32m     95\u001b[0m         type_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minfinity\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m allow_nan \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNaN, infinity\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 96\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     97\u001b[0m                 msg_err\u001b[38;5;241m.\u001b[39mformat\n\u001b[1;32m     98\u001b[0m                 (type_err,\n\u001b[1;32m     99\u001b[0m                  msg_dtype \u001b[38;5;28;01mif\u001b[39;00m msg_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    100\u001b[0m         )\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan:\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache() # PyTorch thing\n",
    "\n",
    "loads=[True, True, True, False] # [csv, xgb, d1cnn, tabnet]\n",
    "#nof=9\n",
    "ftag = \"\".join([str(i) for i in range(nof)])\n",
    "tag='xgb'\n",
    "ROUNDS=1200\n",
    "\n",
    "if loads[1]:\n",
    "    print(\"Loading XGBoost model\")\n",
    "#    xgb_model = pickle.load(open(tag+\"X\" + ftag + \"model\", \"rb\"))\n",
    "else:\n",
    "    print(\"Training XGBoost model\")\n",
    "    xgb_model = trainXgbModel(X_train, y_train, X_test, y_test, X_train.columns, ROUNDS)\n",
    "#    pickle.dump(xgb_model, open(tag+\"X\" + ftag + \"model\", \"wb\"))\n",
    "    pickle.dump(xgb_model, open(tag+\"X\" + str(nof) + \"model\", \"wb\"))\n",
    "\n",
    "'''tag='d1cnn'\n",
    "if loads[2]:\n",
    "    print(\"Loading MLP model\")\n",
    "    d1_cnn_model = keras.models.load_model(tag+\"X\" + ftag + \"model\")\n",
    "else:\n",
    "    print(\"Training MLP model\")\n",
    "    d1_cnn_model = trainD1CnnModel(X_train, y_train)\n",
    "    d1_cnn_model.save(tag+\"X\" + ftag + \"model\")\n",
    "'''\n",
    "d1_cnn_model=None\n",
    "\n",
    "tag='tabnet'\n",
    "if loads[3]:\n",
    "    print(\"Loading TabNet model\")\n",
    "    tabNet_model = TabNetClassifier()\n",
    "    tabNet_model.load_model(tag+\"X\" + ftag + \"model.zip\")\n",
    "else:\n",
    "    print(\"Training TabNet model\")\n",
    "#    tabNet_model = trainTabNetModel(X_train, y_train, None)\n",
    "    tabNet_model = trainTabNetModel(X_train_res, y_train_res, tabNetPretrain(X_train))\n",
    "    tabNet_model.save_model(tag+\"X\" + ftag + \"model\")\n",
    "\n",
    "#tabNet_model=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6710098-c7b4-44b2-8d34-08650abd2949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "makePredictions is executed (took: 4.23 seconds)\n",
      "Evaluation of the model\n",
      "The ROC AUC score of XGBoost model is 0.9996\n",
      "The F1 score of XGBoost model at threshold = 0.27 is 0.9675\n",
      "evaluate is executed (took: 0.04 seconds)\n",
      "Prediction distribution\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "makePredictions is executed (took: 0.40 seconds)\n",
      "Evaluation of the model\n",
      "The ROC AUC score of XGBoost model is 0.9401\n",
      "The F1 score of XGBoost model at threshold = 0.27 is 0.8495\n",
      "evaluate is executed (took: 0.01 seconds)\n",
      "Prediction distribution\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###Train Predicitons\n",
    "print(\"Making predictions\")\n",
    "y_xgb_pred, y_d1_cnn_pred, y_tabNet_pred = makePredictions(X_train, xgb_model, d1_cnn_model, tabNet_model)\n",
    "\n",
    "print(\"Evaluation of the model\")\n",
    "evaluate(y_train, y_xgb_pred, y_d1_cnn_pred, y_tabNet_pred)\n",
    "\n",
    "print(\"Prediction distribution\")\n",
    "plotPredictionDistribution(y_xgb_pred, y_d1_cnn_pred, y_tabNet_pred)\n",
    "\n",
    "\n",
    "###Test Predictions\n",
    "print(\"Making predictions\")\n",
    "y_xgb_pred, y_d1_cnn_pred, y_tabNet_pred = makePredictions(X_test, xgb_model, d1_cnn_model, tabNet_model)\n",
    "\n",
    "print(\"Evaluation of the model\")\n",
    "evaluate(y_test, y_xgb_pred, y_d1_cnn_pred, y_tabNet_pred)\n",
    "\n",
    "print(\"Prediction distribution\")\n",
    "plotPredictionDistribution(y_xgb_pred, y_d1_cnn_pred, y_tabNet_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbcaf93d-763d-4a74-9c5a-8a9353fe6bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t0 t1 t2 t3 t4 t5 t6 t7 t8 t9 t10 t11 dropped customer_ID. encoded categories. prepareData is executed (took: 132.01 seconds)\n",
      "Making predictions... makePredictions is executed (took: 94.33 seconds)\n",
      "saved predictions.\n"
     ]
    }
   ],
   "source": [
    "mdf = pd.read_csv(\"mdf13dts.csv\")\n",
    "#mdf = pd.read_csv(\"mdfdtcnt.csv\")\n",
    "testdf = pd.DataFrame()\n",
    "for i in range(12):\n",
    "    print(\"t\" + str(i), end=\" \")\n",
    "    testdf = pd.concat([testdf, pd.read_csv(\"t\" + str(i) + \"13dts.csv\")], ignore_index=True)\n",
    "#    testdf = pd.concat([testdf, mdf], ignore_index=True)\n",
    "#    testdf.drop(testdf[testdf.customer_ID == 'spc'].index, inplace=True)\n",
    "    #print(testdf.columns)\n",
    "cust = testdf[['customer_ID']]\n",
    "testdf.drop(columns=['origmissrcnt', 'totmissrcnt'], inplace=True)\n",
    "#testdf.drop(columns=['D_87201806', 'D_88201806', 'D_88201805', 'D_87201807'], inplace=True)\n",
    "Xtest=prepareData(testdf, False, False, True)\n",
    "print(\"Making predictions...\", end=\" \")\n",
    "y_xgb_pred, y_d1_cnn_pred, y_tabNet_pred = makePredictions(Xtest[X.columns], xgb_model, None, None)\n",
    "pd.concat([cust, pd.DataFrame(y_xgb_pred, columns=[\"Label\"])], axis='columns').to_csv(\"test/t\" + \"01234567891011\" + \".preds\", index=False)\n",
    "print(\"saved predictions.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1346480c-6f71-4501-b3f0-5ad251f95209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t12-0dtcnt.csv dropped customer_ID. encoded categories. prepareData is executed (took: 12.45 seconds)\n",
      "Making predictions... makePredictions is executed (took: 77.69 seconds)\n",
      "saved predictions.\n",
      "t12-1dtcnt.csv dropped customer_ID. encoded categories. prepareData is executed (took: 12.92 seconds)\n",
      "Making predictions... makePredictions is executed (took: 78.13 seconds)\n",
      "saved predictions.\n",
      "t12-2dtcnt.csv dropped customer_ID. encoded categories. prepareData is executed (took: 12.82 seconds)\n",
      "Making predictions... makePredictions is executed (took: 75.14 seconds)\n",
      "saved predictions.\n",
      "t12-3dtcnt.csv dropped customer_ID. encoded categories. prepareData is executed (took: 12.94 seconds)\n",
      "Making predictions... makePredictions is executed (took: 80.32 seconds)\n",
      "saved predictions.\n",
      "t12-4dtcnt.csv dropped customer_ID. encoded categories. prepareData is executed (took: 13.13 seconds)\n",
      "Making predictions... makePredictions is executed (took: 78.64 seconds)\n",
      "saved predictions.\n",
      "t12-5dtcnt.csv dropped customer_ID. encoded categories. prepareData is executed (took: 12.93 seconds)\n",
      "Making predictions... makePredictions is executed (took: 75.15 seconds)\n",
      "saved predictions.\n",
      "t12-6dtcnt.csv dropped customer_ID. encoded categories. prepareData is executed (took: 13.01 seconds)\n",
      "Making predictions... makePredictions is executed (took: 75.24 seconds)\n",
      "saved predictions.\n",
      "t12-7dtcnt.csv dropped customer_ID. encoded categories. prepareData is executed (took: 12.93 seconds)\n",
      "Making predictions... makePredictions is executed (took: 76.99 seconds)\n",
      "saved predictions.\n",
      "t12-8dtcnt.csv dropped customer_ID. encoded categories. prepareData is executed (took: 12.77 seconds)\n",
      "Making predictions... makePredictions is executed (took: 76.65 seconds)\n",
      "saved predictions.\n",
      "t12-9dtcnt.csv dropped customer_ID. encoded categories. prepareData is executed (took: 13.12 seconds)\n",
      "Making predictions... makePredictions is executed (took: 82.88 seconds)\n",
      "saved predictions.\n",
      "t12-10dtcnt.csv dropped customer_ID. encoded categories. prepareData is executed (took: 12.73 seconds)\n",
      "Making predictions... makePredictions is executed (took: 77.79 seconds)\n",
      "saved predictions.\n",
      "t12-11dtcnt.csv dropped customer_ID. encoded categories. prepareData is executed (took: 13.18 seconds)\n",
      "Making predictions... makePredictions is executed (took: 78.64 seconds)\n",
      "saved predictions.\n",
      "t12-12dtcnt.csv dropped customer_ID. encoded categories. prepareData is executed (took: 13.12 seconds)\n",
      "Making predictions... makePredictions is executed (took: 82.37 seconds)\n",
      "saved predictions.\n",
      "t12-13dtcnt.csv dropped customer_ID. encoded categories. prepareData is executed (took: 13.38 seconds)\n",
      "Making predictions... makePredictions is executed (took: 77.19 seconds)\n",
      "saved predictions.\n",
      "t12-14dtcnt.csv dropped customer_ID. encoded categories. prepareData is executed (took: 13.05 seconds)\n",
      "Making predictions... makePredictions is executed (took: 75.46 seconds)\n",
      "saved predictions.\n",
      "t12-15dtcnt.csv dropped customer_ID. encoded categories. prepareData is executed (took: 12.85 seconds)\n",
      "Making predictions... makePredictions is executed (took: 76.98 seconds)\n",
      "saved predictions.\n",
      "t12-16dtcnt.csv dropped customer_ID. encoded categories. prepareData is executed (took: 13.24 seconds)\n",
      "Making predictions... makePredictions is executed (took: 79.07 seconds)\n",
      "saved predictions.\n",
      "t12-17dtcnt.csv dropped customer_ID. encoded categories. prepareData is executed (took: 13.30 seconds)\n",
      "Making predictions... makePredictions is executed (took: 77.53 seconds)\n",
      "saved predictions.\n",
      "t12-18dtcnt.csv dropped customer_ID. encoded categories. prepareData is executed (took: 12.82 seconds)\n",
      "Making predictions... makePredictions is executed (took: 79.54 seconds)\n",
      "saved predictions.\n",
      "t12-19dtcnt.csv dropped customer_ID. encoded categories. prepareData is executed (took: 12.98 seconds)\n",
      "Making predictions... makePredictions is executed (took: 75.91 seconds)\n",
      "saved predictions.\n",
      "t12-20dtcnt.csv dropped customer_ID. encoded categories. prepareData is executed (took: 13.20 seconds)\n",
      "Making predictions... makePredictions is executed (took: 78.32 seconds)\n",
      "saved predictions.\n",
      "t12-21dtcnt.csv dropped customer_ID. encoded categories. prepareData is executed (took: 12.68 seconds)\n",
      "Making predictions... makePredictions is executed (took: 77.02 seconds)\n",
      "saved predictions.\n",
      "t12-22dtcnt.csv dropped customer_ID. encoded categories. prepareData is executed (took: 12.60 seconds)\n",
      "Making predictions... makePredictions is executed (took: 79.38 seconds)\n",
      "saved predictions.\n",
      "t12-23dtcnt.csv dropped customer_ID. encoded categories. prepareData is executed (took: 13.20 seconds)\n",
      "Making predictions... makePredictions is executed (took: 88.05 seconds)\n",
      "saved predictions.\n",
      "t12-24dtcnt.csv dropped customer_ID. encoded categories. prepareData is executed (took: 13.33 seconds)\n",
      "Making predictions... makePredictions is executed (took: 102.67 seconds)\n",
      "saved predictions.\n",
      "t12-25dtcnt.csv dropped customer_ID. encoded categories. prepareData is executed (took: 13.63 seconds)\n",
      "Making predictions... makePredictions is executed (took: 108.58 seconds)\n",
      "saved predictions.\n",
      "t12-26dtcnt.csv dropped customer_ID. encoded categories. prepareData is executed (took: 12.64 seconds)\n",
      "Making predictions... makePredictions is executed (took: 78.30 seconds)\n",
      "saved predictions.\n",
      "t12-27dtcnt.csv dropped customer_ID. encoded categories. prepareData is executed (took: 12.68 seconds)\n",
      "Making predictions... makePredictions is executed (took: 74.38 seconds)\n",
      "saved predictions.\n",
      "t12-28dtcnt.csv dropped customer_ID. encoded categories. prepareData is executed (took: 12.52 seconds)\n",
      "Making predictions... makePredictions is executed (took: 73.55 seconds)\n",
      "saved predictions.\n",
      "t12-29dtcnt.csv dropped customer_ID. encoded categories. prepareData is executed (took: 12.90 seconds)\n",
      "Making predictions... makePredictions is executed (took: 75.78 seconds)\n",
      "saved predictions.\n",
      "t12-30dtcnt.csv dropped customer_ID. encoded categories. prepareData is executed (took: 12.78 seconds)\n",
      "Making predictions... makePredictions is executed (took: 74.18 seconds)\n",
      "saved predictions.\n",
      "t12-31dtcnt.csv dropped customer_ID. encoded categories. prepareData is executed (took: 13.11 seconds)\n",
      "Making predictions... makePredictions is executed (took: 74.49 seconds)\n",
      "saved predictions.\n",
      "t12-32dtcnt.csv dropped customer_ID. encoded categories. prepareData is executed (took: 13.04 seconds)\n",
      "Making predictions... makePredictions is executed (took: 79.37 seconds)\n",
      "saved predictions.\n",
      "t12-33dtcnt.csv dropped customer_ID. encoded categories. prepareData is executed (took: 12.91 seconds)\n",
      "Making predictions... makePredictions is executed (took: 74.88 seconds)\n",
      "saved predictions.\n",
      "t12-34dtcnt.csv dropped customer_ID. encoded categories. prepareData is executed (took: 12.70 seconds)\n",
      "Making predictions... makePredictions is executed (took: 75.34 seconds)\n",
      "saved predictions.\n",
      "t12-35dtcnt.csv dropped customer_ID. encoded categories. prepareData is executed (took: 12.63 seconds)\n",
      "Making predictions... makePredictions is executed (took: 76.93 seconds)\n",
      "saved predictions.\n",
      "t12-36dtcnt.csv dropped customer_ID. encoded categories. prepareData is executed (took: 12.49 seconds)\n",
      "Making predictions... makePredictions is executed (took: 74.65 seconds)\n",
      "saved predictions.\n",
      "t12-37dtcnt.csv dropped customer_ID. encoded categories. prepareData is executed (took: 13.39 seconds)\n",
      "Making predictions... makePredictions is executed (took: 78.95 seconds)\n",
      "saved predictions.\n",
      "t12-38dtcnt.csv dropped customer_ID. encoded categories. prepareData is executed (took: 12.71 seconds)\n",
      "Making predictions... makePredictions is executed (took: 83.76 seconds)\n",
      "saved predictions.\n",
      "t12-39dtcnt.csv dropped customer_ID. encoded categories. prepareData is executed (took: 13.09 seconds)\n",
      "Making predictions... makePredictions is executed (took: 83.31 seconds)\n",
      "saved predictions.\n",
      "t12-40dtcnt.csv dropped customer_ID. encoded categories. prepareData is executed (took: 12.76 seconds)\n",
      "Making predictions... makePredictions is executed (took: 87.41 seconds)\n",
      "saved predictions.\n"
     ]
    }
   ],
   "source": [
    "for i in range(41):\n",
    "    print(\"t12-\" + str(i) + \"dtcnt.csv\", end=\" \")\n",
    "    testdf = pd.read_csv(\"t12-\" + str(i) + \"dtcnt.csv\")\n",
    "    cust = testdf[['customer_ID']]\n",
    "    testdf.drop(columns=['origmissrcnt', 'totmissrcnt'], inplace=True)\n",
    "    X=prepareData(testdf, False, False, True)\n",
    "    print(\"Making predictions...\", end=\" \")\n",
    "    y_xgb_pred, y_d1_cnn_pred, y_tabNet_pred = makePredictions(X, xgb_model, None, None)\n",
    "    pd.concat([cust, pd.DataFrame(y_xgb_pred, columns=[\"Label\"])], axis='columns').to_csv(\"test/t12-\" + str(i) + \".preds\", index=False)\n",
    "    print(\"saved predictions.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33827a2d-82c5-4671-b721-c3a31be26a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5 14089 0.5 5345 0.26676981433419844\n",
      "1 0.5 28000 0.5 10855 0.2709347310620242\n",
      "2 0.5 42058 0.5 16256 0.27050953506173664\n",
      "3 0.5 56041 0.5 21706 0.27089495426011206\n",
      "4 0.5 70063 0.5 27101 0.27057977815273715\n",
      "5 0.5 84064 0.5 32525 0.27062220225317424\n",
      "6 0.5 97942 0.5 38091 0.2716594397215724\n",
      "7 0.5 111974 0.5 43463 0.2712250463347208\n",
      "8 0.5 125927 0.5 48917 0.27134504870309967\n",
      "9 0.5 139947 0.5 54333 0.2712405086040347\n",
      "10 0.5 153928 0.5 59773 0.2712712848999746\n",
      "11 0.5 167897 0.5 65228 0.2713559477156811\n",
      "12 0.5 182059 0.5 70492 0.27070140742305254\n",
      "13 0.5 195905 0.5 76102 0.2713664241905577\n",
      "14 0.5 209937 0.5 81506 0.27126169001897027\n",
      "15 0.5 223924 0.5 86970 0.2713513277401118\n",
      "16 0.5 237950 0.5 92370 0.27124965128400896\n",
      "17 0.5 251892 0.5 97859 0.27140309567985976\n",
      "18 0.5 265855 0.5 103272 0.2713421282879266\n",
      "19 0.5 279799 0.5 108702 0.2713310452418097\n",
      "20 0.5 293843 0.5 114098 0.2712401908461368\n",
      "21 0.5 307894 0.5 119485 0.27113286497476674\n",
      "22 0.5 321986 0.5 124831 0.2709523520116689\n",
      "23 0.5 335951 0.5 130305 0.27104806082226546\n",
      "24 0.5 349959 0.5 135744 0.27106784484049723\n",
      "25 0.5 363903 0.5 141214 0.2711461509512216\n",
      "26 0.5 377932 0.5 146635 0.2711275548504717\n",
      "27 0.5 391919 0.5 152097 0.2711833884863354\n",
      "28 0.5 405929 0.5 157537 0.27119516473603844\n",
      "29 0.5 419972 0.5 162972 0.27120009185777355\n",
      "30 0.5 434006 0.5 168377 0.27115638874708314\n",
      "31 0.5 448028 0.5 173795 0.2711331601650559\n",
      "32 0.5 462030 0.5 179237 0.2711496975913202\n",
      "33 0.5 475932 0.5 184787 0.27132463604261037\n",
      "34 0.5 489947 0.5 190191 0.27128094310960865\n",
      "35 0.5 504005 0.5 195541 0.27116479341020505\n",
      "36 0.5 518086 0.5 200864 0.2710170289644862\n",
      "37 0.5 532081 0.5 206294 0.27101832547055166\n",
      "38 0.5 546167 0.5 211639 0.2709110971157637\n",
      "39 0.5 560171 0.5 217092 0.27094402072779417\n",
      "40 0.5 573355 0.5 222396 0.27111941171881093\n",
      "\n",
      "0.1 359647 0.9 70703 0.08619289810408051\n",
      "0.2 470233 0.8 128968 0.1572228290551611\n",
      "0.3 516222 0.7 167319 0.20397592065225872\n",
      "0.4 547507 0.6 196691 0.23978285675275024\n",
      "0.5 573355 0.5 222396 0.27111941171881093\n"
     ]
    }
   ],
   "source": [
    "preds=pd.DataFrame()\n",
    "cutoff=0.5\n",
    "for i in range(41):\n",
    "    preds = pd.concat([preds, pd.read_csv(\"test/t12-\" + str(i) + \".preds\")])\n",
    "    print(i, round(1-cutoff, 1), preds[round(preds['Label'],1) < round((1-cutoff),1) ]['Label'].count(), round(cutoff, 1), preds[round(preds['Label'], 1) > round(cutoff,1)]['Label'].count(), (preds[round(preds['Label'],1) > round(cutoff, 1)]['Label'].count() / preds['Label'].count()))\n",
    "print(\"\")\n",
    "cutoff=0.9\n",
    "for i in range(5):\n",
    "    print(round(1-cutoff, 1), preds[round(preds['Label'],1) < round((1-cutoff),1) ]['Label'].count(), round(cutoff, 1), preds[round(preds['Label'], 1) > round(cutoff,1)]['Label'].count(), (preds[round(preds['Label'],1) > round(cutoff, 1)]['Label'].count() / preds['Label'].count()))\n",
    "    cutoff-=0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8801a0da-22bd-4c3c-9045-c5f21e7ce3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00024152208 0.99981505\n",
      "0.00023186119679999997 0.959822448\n",
      "\n",
      "preds min max: (0.00023186119679999997, 0.99993396)\n"
     ]
    }
   ],
   "source": [
    "root=\"/home/paperspace/amex-default-prediction/\"\n",
    "\n",
    "samples = pd.read_csv(root + \"sample_submission.csv\")\n",
    "\n",
    "preddf= pd.DataFrame()\n",
    "rangemin, rangemax = 0, 1\n",
    "\n",
    "preds = pd.read_csv(root+\"/test/t\"+ \"01234567891011\" + \".preds\")\n",
    "print(preds['Label'].min(), preds['Label'].max())\n",
    "preds['Label'] = ( (preds[['Label']] - rangemin) / (rangemax - rangemin) ) * (0.96 - 0) + 0\n",
    "print(preds['Label'].min(), preds['Label'].max())\n",
    "preddf = pd.concat([preddf, preds], ignore_index=True, axis=0)\n",
    "\n",
    "for i in range(0):\n",
    "#    preds = pd.read_csv(root+\"/test/x\"+ str(i) + \"13dtsnew.preds\")\n",
    "#    rangemin = preds['Label'].min()\n",
    "#    rangemax = preds['Label'].max()\n",
    "#    rangemin = min(preds['Label'].min(), rangemin)\n",
    "#    rangemax = max(preds['Label'].max(), rangemax)\n",
    "    preds = pd.read_csv(root+\"/test/t\"+ str(i) + \".preds\")\n",
    "#    rangemin = min(preds['Label'].min(), rangemin)\n",
    "#    rangemax = max(preds['Label'].max(), rangemax)\n",
    "#    preds['Label'] = ( (preds[['Label']] - rangemin) / (rangemax - rangemin) ) * (1 - 0) + 0\n",
    "    print(i, preds['Label'].min(), preds['Label'].max(), \"actual:\", rangemin, rangemax, \"1:\", preds[(round(preds['Label']) == 1)].count()[0], \"0:\", preds[(round(preds['Label']) == 0)].count()[0])\n",
    "    cutoff=0.9\n",
    "    for j in range(5):\n",
    "        print(i, round(1-cutoff, 1), preds[round(preds['Label'],1) < round((1-cutoff),1) ]['Label'].count(), round(cutoff, 1), preds[round(preds['Label'], 1) > round(cutoff,1)]['Label'].count(), (preds[round(preds['Label'],1) > round(cutoff, 1)]['Label'].count() / preds['Label'].count()))\n",
    "        cutoff-=0.1\n",
    "    preddf = pd.concat([preddf, preds], ignore_index=True, axis=0)\n",
    "print(\"\")\n",
    "for i in range(41):\n",
    "    preds = pd.read_csv(root+\"/test/t12-\"+ str(i) + \".preds\") #.rename(columns={\"prediction\":\"Label\"}).drop(columns=\"Unnamed: 0\")\n",
    "    if (preds['Label'].agg(['min', 'max'])[0] < 0) or (preds['Label'].agg(['min', 'max'])[1]>1):\n",
    "        print(i, preds['Label'].agg(['min', 'max'])[0], preds['Label'].agg(['min', 'max'])[1])\n",
    "        rangemin = min(preds['Label'].min(), rangemin)\n",
    "        rangemax = max(preds['Label'].max(), rangemax)\n",
    "        preds['Label'] = ( (preds[['Label']] - rangemin) / (rangemax - rangemin) ) * (1 - 0) + 0\n",
    "    preddf = pd.concat([preddf, preds], ignore_index=True, axis=0)\n",
    "\n",
    "print(\"preds min max:\", (preddf['Label'].min(), preddf['Label'].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f31ee7dc-822a-4a46-b87e-939c4da2b25f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matching 1's 0 0\n",
      "matching 0's 641095 924621\n",
      "matching 641095 total 924621 % 0.6933597657851163\n"
     ]
    }
   ],
   "source": [
    "valids = pd.merge(samples, preddf, on='customer_ID', how='inner')\n",
    "valids.rename(columns={'prediction': 'target'}, inplace=True)\n",
    "valids.rename(columns={'Label': 'prediction'}, inplace=True)\n",
    "\n",
    "valids['prediction'].fillna(0, inplace=True)\n",
    "\n",
    "print(\"matching 1's\", valids[(valids['target'] == round(valids['prediction'])) & (valids['target'] == 1)].count()[0], valids[(valids['target'] == 1)].count()[0])\n",
    "print(\"matching 0's\", valids[(valids['target'] == round(valids['prediction'])) & (valids['target'] == 0)].count()[0], valids[(valids['target'] == 0)].count()[0])\n",
    "print(\"matching\", valids[valids['target'] == round(valids['prediction'])].count()[0], \"total\", valids.count()[0], \"%\", valids[valids['target'] == round(valids['prediction'])].count()[0]/valids.count()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5a2de17b-7d6c-460a-9605-8beac8adbd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valids[['customer_ID', 'prediction']].to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b06a681-a87d-4489-b90f-d4fef002231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(valids['customer_ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a8dedc-720d-432e-b98c-7005ba9f087f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
